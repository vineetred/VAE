{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEGIN THE NORMAL MNIST CLASSIFICTION\n",
    "# dependencies (numpy, matplotlib, and keras)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from keras.layers import Input, Dense, Lambda, MaxPool2D, Conv2D,Conv1D, Flatten\n",
    "from keras.models import Model,Sequential\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000, 28, 28, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparaters\n",
    "features = 2\n",
    "batch_size = 100\n",
    "epochs = 5\n",
    "\n",
    "#Prep data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test,10)\n",
    "\n",
    "X_part1, X_part3, y_part1, y_part3 = train_test_split(x_train, y_train, test_size=0.1)\n",
    "X_part1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),\n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "# model.add(Conv2D(filters = 32, kernel_size = (5,5),\n",
    "#                  activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "# model.add(Conv2D(filters = 64, kernel_size = (3,3),\n",
    "#                  activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),\n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 53s 982us/step - loss: 0.2472 - acc: 0.9227 - val_loss: 0.0571 - val_acc: 0.9818\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 53s 987us/step - loss: 0.0819 - acc: 0.9744 - val_loss: 0.0457 - val_acc: 0.9857\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 58s 1ms/step - loss: 0.0610 - acc: 0.9814 - val_loss: 0.0361 - val_acc: 0.9888\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 53s 979us/step - loss: 0.0530 - acc: 0.9841 - val_loss: 0.0339 - val_acc: 0.9897\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 52s 955us/step - loss: 0.0478 - acc: 0.9862 - val_loss: 0.0315 - val_acc: 0.9918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1246fdf28>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'rmsprop' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(X_part1,y_part1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data = (X_part3,y_part3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
